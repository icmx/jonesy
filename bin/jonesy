#!/usr/bin/python3

from datetime       import datetime
from http.server    import BaseHTTPRequestHandler
from http.server    import HTTPServer
from os             import environ
from os.path        import join
from os.path        import realpath
from sys            import argv
from urllib.request import Request
from urllib.request import urlopen
from xml.etree      import ElementTree
from queue          import Queue
from threading      import Thread

HOST      = None
PORT      = None
HOME      = None
USERAGENT = None
THREADS   = None
MODE      = None

# Templates
VIEW_FETCH = '''<?xml version="1.0" encoding="utf-8"?>
    <feed xmlns="http://www.w3.org/2005/Atom">
        <title>Jonesy Bumper Feed</title>
        <subtitle>
            This feed is a backup update trigger — if you access it,
            then jonesy will execute fetch mode and update all your
            feeds. It's better to use external schedulers however ­—
            such as at, Cron or systemd service.
        </subtitle>
        <updated>{date}</updated>
        <entry>
            <title>Update started at {date}</title>
            <updated>{date}</updated>
            <content type="html">
                &lt;p&gt;
                    If you can read this, then your local feeds are
                    already updated.
                &lt;/p&gt;
            </content>
        </entry>
    </feed>
'''

VIEW_INDEX = '''<!doctype html>
    <html>
        <head>
            <meta name="viewport" content="width=device-width" />
            <meta charset="utf-8" />
            <title>It works! - jonesy</title>
            <style>
                body {{
                    background-color: #EEE;
                    color:            #444;
                    font-size:        18px;
                    line-height:      1.5;
                    margin:           60px auto;
                    max-width:        720px;
                    padding:          0 16px;
                }}
            </style>
        </head>
        <body>
            <h1>
                It works!
            </h1>
            <p>
                Jonesy is serving on <a href="/">{host}:{port}</a>.
            </p>
            <ul>
                <li>
                    Feeds are available in <a href="/feeds">/feeds</a>
                    directory. There is no directory listing however, so
                    you should know the exact feed file name (e.g.
                    /feeds/reddit.feed)
                </li>
                <li>
                    You can refresh them manually by accessing
                    <a href="/fetch">/fetch</a> path. Note that
                    refreshing will take a while if your feeds list is
                    quite long
                </li>
            </ul>
        </body>
    </html>
'''


# Input/Output Utilities
def io_read(path, mode):
    file = open(path, mode)
    data = file.read()
    file.close()
    return data

def io_write(path, mode, data):
    file = open(path, mode)
    file.write(data)
    file.close()

def io_fetch(source, output):
    request = Request(source, headers={ 'User-Agent': USERAGENT })
    sh_log('{0}: accessing ...'.format(source))

    try:
        response = urlopen(request)
        data     = response.read()
        sh_log('{0}: saving to {1} ...'.format(source, output))
        io_write(join(HOME, 'feeds', output), 'wb', data)
    except Exception as exception:
        sh_log('{0}: exception: {1}'.format(source, exception))
    else:
        sh_log('{0}: ok.'.format(source))


# Shell Utilities
def sh_timestamp():
    return datetime.now().replace(microsecond=0).isoformat()

def sh_log(message):
    timestamp = sh_timestamp()
    print('jonesy: {0}: {1}'.format(timestamp, message))

def sh_getenv(key, value=None):
    return environ.get(key, value)

def sh_getstr(key, value=None):
    return sh_getenv(key, value)

def sh_getint(key, value=None):
    return int(sh_getenv(key, value))


# XML Utilities
def xml_get_opml(path):
    feeds = ElementTree.parse(path)

    for feed in feeds.iter('outline'):
        source = feed.get('xmlUrl')
        output = feed.get('text')
        yield (source, output)

def xml_get_muon(path):
    feeds = ElementTree.parse(path)

    for feed in feeds.iter('feed'):
        if feed.get('enabled') != 'false':
            source = feed.get('source')
            output = feed.get('output')
            yield (source, output)


class JonesyFetchWorker(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue

    def run(self):
        while True:
            source, output = self.queue.get()
            io_fetch(source, output)
            self.queue.task_done()

class JonesyRequestHandler(BaseHTTPRequestHandler):
    def send_headers_ok(self, content_type):
        self.send_response(200)
        self.send_header('Content-Type', content_type)
        self.end_headers()

    def send_headers_fail(self):
        self.send_response(400)
        self.end_headers()

    def send_payload_string(self, data, content_type):
        self.send_headers_ok(content_type)
        self.wfile.write(bytes(data, 'utf-8'))

    def send_payload_file(self, path, content_type):
        try:
            data = io_read(realpath(path), 'rb')
        except:
            self.send_headers_fail()
        else:
            self.send_headers_ok(content_type)
            self.wfile.write(data)

    def log_message(*args):
        pass

    def do_GET(self):
        sh_log('accessing to path {0}'.format(self.path))

        if   self.path == '/':
            response = VIEW_INDEX.format(host=HOST, port=PORT)
            self.send_payload_string(response, 'text/html')
        elif self.path == '/fetch':
            do_mode_fetch()
            date = sh_timestamp()
            response = VIEW_FETCH.format(date=date)
            self.send_payload_string(response, 'application/xml')
        elif self.path == '/feeds':
            response = HOME + self.path + '.' + MODE
            self.send_payload_file(response, 'application/xml')
        else:
            response = HOME + self.path
            self.send_payload_file(response, 'application/xml')


def do_mode_fetch():
    queue = Queue()

    if   MODE == 'muon':
        feeds = [i for i in xml_get_muon(join(HOME, 'feeds.muon'))]
    elif MODE == 'opml':
        feeds = [i for i in xml_get_opml(join(HOME, 'feeds.opml'))]

    for i in range(THREADS):
        worker = JonesyFetchWorker(queue)
        worker.daemon = True
        worker.start()

    for feed in feeds:
        queue.put(feed)

    queue.join()


def do_mode_serve():
    sh_log('starting at http://{0}:{1} ...'.format(HOST, PORT))

    try:
        server = HTTPServer((HOST, PORT), JonesyRequestHandler)
        server.serve_forever()
    except Exception as exception:
        sh_log('unable to start: {0}'.format(exception))
    else:
        sh_log('serving, press Ctrl+C to stop.')


def main():
    if   len(argv) == 1:
        print('Usage: jonesy {fetch,serve}')
    elif argv[1]   == 'serve':
        do_mode_serve()
    elif argv[1]   == 'fetch':
        do_mode_fetch()
    elif argv[1]   == 'setup':
        do_mode_setup()
    else:
        print('{0}: unknown mode. Exiting.'.format(argv[1]))


if __name__ == '__main__':
    HOME      = sh_getstr('HOME')
    HOME      = sh_getstr('XDG_CONFIG_HOME',  join(HOME + '.jonesy'))
    HOME      = sh_getstr('JONESY_HOME',      join(HOME + '/jonesy'))

    HOST      = sh_getstr('JONESY_HOST',      '127.0.0.1')
    PORT      = sh_getint('JONESY_PORT',      '8600')
    USERAGENT = sh_getstr('JONESY_USERAGENT', 'Mozilla/5.0 (Windows ' +\
                                              'NT 10.0; Win64; x64; ' +\
                                              'rv:59.0) ')
    THREADS   = sh_getint('JONESY_THREADS',   '4')
    MODE      = sh_getstr('JONESY_MODE',      'muon')

    main()
