#!/usr/bin/env python3

from configparser   import ConfigParser
from datetime       import datetime
from http.server    import BaseHTTPRequestHandler
from http.server    import HTTPServer
from os             import environ
from os.path        import join
from os.path        import realpath
from sys            import argv
from urllib.request import Request
from urllib.request import urlopen
from xml.etree      import ElementTree

HOST = None
PORT = None
HOME = None
BUAS = None

VIEW_FETCH = '''<?xml version="1.0" encoding="utf-8"?>
    <feed xmlns="http://www.w3.org/2005/Atom">
        <title>Jonesy Bumper Feed</title>
        <subtitle>
            This feed is a backup update trigger — if you access it,
            then jonesy will execute fetch mode and update all your
            feeds. It's better to use external schedulers however ­—
            such as at, Cron or systemd service.
        </subtitle>
        <updated>{date}</updated>
        <entry>
            <title>Update started at {date}</title>
            <updated>{date}</updated>
            <content type="html">
                &lt;p&gt;
                    If you can read this, then your local feeds are
                    already updated.
                &lt;/p&gt;
            </content>
        </entry>
    </feed>
'''

VIEW_INDEX = '''<!doctype html>
    <html>
        <head>
            <meta name="viewport" content="width=device-width" />
            <meta charset="utf-8" />
            <title>It works!</title>
            <style>
                body {{
                    background-color: #EEE;
                    color:            #444;
                    font-size:        18px;
                    line-height:      1.5;
                    margin:           60px auto;
                    max-width:        720px;
                    padding:          0 16px;
                }}
            </style>
        </head>
        <body>
            <h1>
                It works!
            </h1>
            <p>
                Jonesy is serving on <a href="/">{host}:{port}</a>.
            </p>
            <ul>
                <li>
                    Feeds are available in <a href="/feeds">/feeds</a>
                    directory. There is no directory listing however, so
                    you should know the exact feed file name (e.g.
                    /feeds/reddit.feed)
                </li>
                <li>
                    You can refresh them manually by accessing
                    <a href="/fetch">/fetch</a> path. Note that
                    refreshing will take a while if your feeds list is
                    quite long
                </li>
            </ul>
        </body>
    </html>
'''

class CustomHTTPRequesHandler(BaseHTTPRequestHandler):
    def send_headers_ok(self, content_type):
        self.send_response(200)
        self.send_header('Content-Type', content_type)
        self.end_headers()

    def send_headers_fail(self):
        self.send_response(400)
        self.end_headers()

    def send_payload_string(self, data, content_type):
        self.send_headers_ok(content_type)
        self.wfile.write(bytes(data, 'utf-8'))

    def send_payload_file(self, path, content_type):
        try:
            data = read(realpath(path), 'rb')
        except:
            self.send_headers_fail()
        else:
            self.send_headers_ok(content_type)
            self.wfile.write(data)

    def log_message(*args):
        pass

    def do_GET(self):
        log('Accessing to path {0}'.format(self.path))

        if   self.path == '/':
            response = VIEW_INDEX.format(host=HOST, port=PORT)
            self.send_payload_string(response, 'text/html')
        elif self.path == '/fetch':
            do_mode_fetch()
            date = get_timestamp()
            response = VIEW_FETCH.format(date=date)
            self.send_payload_string(response, 'application/xml')
        else:
            self.send_payload_file(HOME + self.path, 'application/xml')

def get_timestamp():
    return datetime.now().replace(microsecond=0).isoformat()

def log(message):
    timestamp = get_timestamp()
    print('jonesy: {0}: {1}'.format(timestamp, message))

def read(path, mode):
    file = open(path, mode)
    data = file.read()
    file.close()
    return data

def write(path, mode, data):
    file = open(path, mode)
    file.write(data)
    file.close()


def do_mode_fetch():
    feeds = ElementTree.parse(join(HOME + '/feeds.muon'))

    for feed in feeds.iter('feed'):
        if feed.get('enabled') != 'false':
            source = feed.get('source')
            output = feed.get('output')

            log('Trying to update {0} ...'.format(source))

            request = Request(source, headers={'User-Agent': BUAS})

            try:
                response = urlopen(request)
                data = response.read()
                write(join(HOME + '/feeds/' + output), 'wb', data)
            except Exception as exception:
                log(exception)
            else:
                log('OK.')

    log('End of feeds list.')


def do_mode_serve():
    log('starting at http://{0}:{1} ...'.format(HOST, PORT))

    server = HTTPServer((HOST, PORT), CustomHTTPRequesHandler)
    server.serve_forever()

    log('serving. Press Ctrl+C to stop.')


def main():
    if   len(argv) == 1:
        print('Usage: jonesy {fetch,serve}')
    elif argv[1]   == 'serve':
        do_mode_serve()
    elif argv[1]   == 'fetch':
        do_mode_fetch()
    else:
        print('{0}: unknown mode. Exiting.'.format(argv[1]))

if __name__ == '__main__':
    HOME = environ.get('HOME')
    HOME = environ.get('XDG_CONFIG_HOME', join(HOME + '.jonesy'))
    HOME = environ.get('JONESY_HOME',     join(HOME + '/jonesy'))

    config = ConfigParser()
    config.read(join(HOME + '/config.ini'))

    BUAS = config.get('fetch', 'useragent')
    HOST = config.get('serve', 'host')
    PORT = config.getint('serve', 'port')

    main()
