#!/usr/bin/python3

from datetime       import datetime
from http.server    import BaseHTTPRequestHandler
from http.server    import HTTPServer
from os             import environ
from os.path        import join
from os.path        import realpath
from sys            import argv
from urllib.request import Request
from urllib.request import urlopen
from xml.etree      import ElementTree
from queue          import Queue
from threading      import Thread

HOST      = None
PORT      = None
HOME      = None
USERAGENT = None
THREADS   = None

VIEW_FETCH = '''<?xml version="1.0" encoding="utf-8"?>
    <feed xmlns="http://www.w3.org/2005/Atom">
        <title>Jonesy Bumper Feed</title>
        <subtitle>
            This feed is a backup update trigger — if you access it,
            then jonesy will execute fetch mode and update all your
            feeds. It's better to use external schedulers however ­—
            such as at, Cron or systemd service.
        </subtitle>
        <updated>{date}</updated>
        <entry>
            <title>Update started at {date}</title>
            <updated>{date}</updated>
            <content type="html">
                &lt;p&gt;
                    If you can read this, then your local feeds are
                    already updated.
                &lt;/p&gt;
            </content>
        </entry>
    </feed>
'''

VIEW_INDEX = '''<!doctype html>
    <html>
        <head>
            <meta name="viewport" content="width=device-width" />
            <meta charset="utf-8" />
            <title>It works! - jonesy</title>
            <style>
                body {{
                    background-color: #EEE;
                    color:            #444;
                    font-size:        18px;
                    line-height:      1.5;
                    margin:           60px auto;
                    max-width:        720px;
                    padding:          0 16px;
                }}
            </style>
        </head>
        <body>
            <h1>
                It works!
            </h1>
            <p>
                Jonesy is serving on <a href="/">{host}:{port}</a>.
            </p>
            <ul>
                <li>
                    Feeds are available in <a href="/feeds">/feeds</a>
                    directory. There is no directory listing however, so
                    you should know the exact feed file name (e.g.
                    /feeds/reddit.feed)
                </li>
                <li>
                    You can refresh them manually by accessing
                    <a href="/fetch">/fetch</a> path. Note that
                    refreshing will take a while if your feeds list is
                    quite long
                </li>
            </ul>
        </body>
    </html>
'''


class IO():
    def read(path, mode):
        file = open(path, mode)
        data = file.read()
        file.close()
        return data

    def write(path, mode, data):
        file = open(path, mode)
        file.write(data)
        file.close()

    def fetch(source, output):
        request = Request(source, headers={'User-Agent': USERAGENT})

        try:
            Sh.log('{0}: accessing ...'.format(source))
            response = urlopen(request)
            data = response.read()
            Sh.log('{0}: saving to {1} ...'.format(source, output))
            IO.write(join(HOME, 'feeds', output), 'wb', data)
        except Exception as exception:
            Sh.log('{0}: exception: {1}'.format(source, exception))
        else:
            Sh.log('{0}: ok.'.format(source))


class Sh():
    def timestamp():
        return datetime.now().replace(microsecond=0).isoformat()

    def log(message):
        timestamp = Sh.timestamp()
        print('jonesy: {0}: {1}'.format(timestamp, message))

    def get(key, value=None):
        return environ.get(key, value)

    def getstr(key, value=None):
        return Sh.get(key, value)

    def getint(key, value=None):
        return int(Sh.getstr(key, value))

class JonesyFetchThread(Thread):
    def __init__(self, queue):
        Thread.__init__(self)
        self.queue = queue

    def run(self):
        while True:
            source, output = self.queue.get()
            IO.fetch(source, output)
            self.queue.task_done()


class JonesyHTTPRequestHandler(BaseHTTPRequestHandler):
    def send_headers_ok(self, content_type):
        self.send_response(200)
        self.send_header('Content-Type', content_type)
        self.end_headers()

    def send_headers_fail(self):
        self.send_response(400)
        self.end_headers()

    def send_payload_string(self, data, content_type):
        self.send_headers_ok(content_type)
        self.wfile.write(bytes(data, 'utf-8'))

    def send_payload_file(self, path, content_type):
        try:
            data = read(realpath(path), 'rb')
        except:
            self.send_headers_fail()
        else:
            self.send_headers_ok(content_type)
            self.wfile.write(data)

    def log_message(*args):
        pass

    def do_GET(self):
        Sh.log('accessing to path {0}'.format(self.path))

        if   self.path == '/':
            response = VIEW_INDEX.format(host=HOST, port=PORT)
            self.send_payload_string(response, 'text/html')
        elif self.path == '/fetch':
            do_mode_fetch()
            date = Sh.timestamp()
            response = VIEW_FETCH.format(date=date)
            self.send_payload_string(response, 'application/xml')
        else:
            response = join(HOME, self.path)
            self.send_payload_file(response, 'application/xml')


def do_mode_fetch():
    queue = Queue()
    feeds = ElementTree.parse(join(HOME + '/feeds.muon'))

    for i in range(THREADS):
        worker = JonesyFetchThread(queue)
        worker.daemon = True
        worker.start()

    for feed in feeds.iter('feed'):
        if feed.get('enabled') != 'false':
            source = feed.get('source')
            output = feed.get('output')
            queue.put((source, output))

    queue.join()


def do_mode_serve():
    Sh.log('starting at http://{0}:{1} ...'.format(HOST, PORT))

    try:
        server = HTTPServer((HOST, PORT), JonesyHTTPRequestHandler)
        server.serve_forever()
    except Exception as exception:
        Sh.log('unable to start: {0}'.format(exception))
    else:
        Sh.log('serving, press Ctrl+C to stop.')

def main():
    if   len(argv) == 1:
        print('Usage: jonesy {fetch,serve}')
    elif argv[1]   == 'serve':
        do_mode_serve()
    elif argv[1]   == 'fetch':
        do_mode_fetch()
    else:
        print('{0}: unknown mode. Exiting.'.format(argv[1]))

if __name__ == '__main__':
    HOME      = Sh.getstr('HOME')
    HOME      = Sh.getstr('XDG_CONFIG_HOME', join(HOME + '.jonesy'))
    HOME      = Sh.getstr('JONESY_HOME',     join(HOME + '/jonesy'))

    HOST      = Sh.getstr('JONESY_HOST',      '127.0.0.1')
    PORT      = Sh.getint('JONESY_PORT',      '8600')
    USERAGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:59.0) ' +\
                'Gecko/20100101 Firefox/59.0'
    USERAGENT = Sh.getstr('JONESY_USERAGENT', USERAGENT)
    THREADS   = Sh.getint('JONESY_THREADS',   '4')

    main()
